{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "880bac95-a3cc-4ad8-ac25-c243b69ac6ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_datasets as tfds\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fdc6981-b95e-48c8-aa3a-0fa7409f4900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_21180\\176556895.py:4: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# as_supervised = True , means dataset directly (input, label) pairs return karega:,\n",
    "\"\"\" else dictionary,example= {'image': <tf.Tensor: shape=(28, 28, 1), dtype=uint8, numpy=...>,\n",
    "'label': <tf.Tensor: shape=(), dtype=int64, numpy=5>}\n",
    "\"\"\"\n",
    "# \n",
    "''' ''''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03439918-d0ba-4feb-8d96-c0fccc8626ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imbd dataset (pre-defined dataset) ko load krna\n",
    "(train_data , validate_data , test ) = tfds.load(name = 'imdb_reviews' , \n",
    "                                                 split = ('train[:60%]','train[60:]','test'),\n",
    "                                                 as_supervised = True\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b3a79d4-414e-47da-8f81-9dd8a8d311c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int64, numpy=array([0, 0, 0, 1, 1, 1, 0, 0, 0, 0])>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_example_batch , train_labels_batch = next(iter(train_data.batch(10)))\n",
    "#iter() function se dataset ka iterator banaya jata hai, \n",
    "# jo ek-ek batch return karega. ,,isme batch size 10 hai\n",
    "# while \n",
    "# next() function iterator ka first batch return karega.\n",
    "# Ye batch ek tuple hota hai: (inputs, labels), jisme:\n",
    "# inputs → Training examples (features)\n",
    "# labels → Unka corresponding output (class labels)\n",
    "\"\"\"\n",
    "Ye code dataset ke first 10 training examples & labels ko extract karta hai \n",
    "batch-wise training ke liye! , \n",
    "while \n",
    "train_example_batch --→ First 10 training examples (features)\n",
    "train_labels_batch --→ First 10 labels (outputs)\n",
    "\"\"\"\n",
    "train_labels_batch\n",
    "# 📌 1. Data Load & Preprocessing -> done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8bff43e0-a2a5-406f-beec-8dee8139f960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Layer Loaded ✅\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 20), dtype=float32, numpy=\n",
       "array([[ 1.765786  , -3.882232  ,  3.9134233 , -1.5557289 , -3.3362343 ,\n",
       "        -1.7357955 , -1.9954445 ,  1.2989551 ,  5.081598  , -1.1041286 ,\n",
       "        -2.0503852 , -0.72675157, -0.65675956,  0.24436149, -3.7208383 ,\n",
       "         2.0954835 ,  2.2969332 , -2.0689783 , -2.9489717 , -1.1315987 ],\n",
       "       [ 1.8804485 , -2.5852382 ,  3.4066997 ,  1.0982676 , -4.056685  ,\n",
       "        -4.891284  , -2.785554  ,  1.3874227 ,  3.8476458 , -0.9256538 ,\n",
       "        -1.896706  ,  1.2113281 ,  0.11474707,  0.76209456, -4.8791065 ,\n",
       "         2.906149  ,  4.7087674 , -2.3652055 , -3.5015898 , -1.6390051 ],\n",
       "       [ 0.71152234, -0.6353217 ,  1.7385626 , -1.1168286 , -0.5451594 ,\n",
       "        -1.1808156 ,  0.09504455,  1.4653089 ,  0.66059524,  0.79308075,\n",
       "        -2.2268345 ,  0.07446612, -1.4075904 , -0.70645386, -1.907037  ,\n",
       "         1.4419787 ,  1.9551861 , -0.42660055, -2.8022065 ,  0.43727064]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 📌 2. Text Embeddings Using TensorFlow Hub\n",
    "\n",
    "embedding = \"https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1\" \n",
    "# txt data ko number format (embeddings) me convert karna zaroori hai.\n",
    "hub_layer = hub.KerasLayer( embedding, \n",
    "                          input_shape = [] , \n",
    "                          dtype = tf.string ,\n",
    "                          trainable = True)\n",
    "print(\"Embedding Layer Loaded ✅\")\n",
    "\"\"\"  \n",
    "jo strings ko numerical vectors me convert karta hai.\n",
    "Agar trainable=True\n",
    "hai to hum embeddings ko fine-tune bhi kar sakte hain,\n",
    "warna sirf pre-trained vectors ka use hoga. 🚀\n",
    "\"\"\"\n",
    "#Vectors in ai represent \n",
    "# data numerically, enabling machines to process, compare, and learn patterns efficiently.  \n",
    "hub_layer(train_example_batch[:3])\n",
    "# means \n",
    "# First 3 training examples ko embedding layer se pass kar rahe hain \n",
    "# taaki unko numerical vectors me convert kiya ja sake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7dcc8dcf-8c81-4165-9cc0-cc3f02a942f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# 📌 3. Model Create Karna (Using Keras Sequential API)\n",
    "# ✅ Neural Network Model (Using TensorFlow Keras)\n",
    "# ✅ Wrap in a Lambda Layer\n",
    "wrapped_hub_layer = tf.keras.layers.Lambda(lambda x: hub_layer(x))\n",
    "# ✅ Wrapping with Lambda solves this issue by ensuring it acts as a Keras Layer.\n",
    "\n",
    "# ✅ Define Model\n",
    "model = tf.keras.Sequential([\n",
    "    wrapped_hub_layer,  # Wrapping solves the issue\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dense(8, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "# Text input → hub_layer → Embeddings\n",
    "# Embeddings → Dense Layers (MLP) → Output Prediction\n",
    "# Works fine inside Sequential() because of Lambda wrapping.\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "744ace6a-b40b-4c44-8bba-99c0690b9a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Compiled Successfully ✅\n"
     ]
    }
   ],
   "source": [
    "# 📌 4. Model Compile Karna\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',  # Kyuki yeh Binary Classification hai\n",
    "    optimizer='adam',  # Adaptive learning ke liye Adam Optimizer\n",
    "    metrics=['accuracy']  # Accuracy ko track karne ke liye\n",
    ")\n",
    "# Binary Crossentropy: Kyuki yeh binary classification problem hai.\n",
    "# Adam Optimizer: Kyuki yeh best learning rate optimization karta hai.\n",
    "print(\"Model Compiled Successfully ✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8ebe8e59-b51e-4577-8181-995877267bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data: <_PrefetchDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>\n",
      "Validation Data: <_PrefetchDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>\n",
      "Test Data: <_PrefetchDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:From C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:216: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:216: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.4986 - loss: 0.8691 - val_accuracy: 0.5550 - val_loss: 0.7087\n",
      "Epoch 2/10\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.5838 - loss: 0.6894 - val_accuracy: 0.6159 - val_loss: 0.6571\n",
      "Epoch 3/10\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.6294 - loss: 0.6489 - val_accuracy: 0.6393 - val_loss: 0.6371\n",
      "Epoch 4/10\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.6440 - loss: 0.6340 - val_accuracy: 0.6481 - val_loss: 0.6263\n",
      "Epoch 5/10\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.6508 - loss: 0.6252 - val_accuracy: 0.6555 - val_loss: 0.6190\n",
      "Epoch 6/10\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.6577 - loss: 0.6190 - val_accuracy: 0.6609 - val_loss: 0.6134\n",
      "Epoch 7/10\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.6644 - loss: 0.6141 - val_accuracy: 0.6658 - val_loss: 0.6088\n",
      "Epoch 8/10\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.6693 - loss: 0.6099 - val_accuracy: 0.6706 - val_loss: 0.6046\n",
      "Epoch 9/10\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.6712 - loss: 0.6060 - val_accuracy: 0.6764 - val_loss: 0.6007\n",
      "Epoch 10/10\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.6747 - loss: 0.6022 - val_accuracy: 0.6787 - val_loss: 0.5972\n",
      "Model Training Done ✅\n"
     ]
    }
   ],
   "source": [
    "# 📌 5. Model Train Karna\n",
    "# ✅ Train Model\n",
    "# Ab model train karege IMDB dataset ke training data pe.\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "(train_data, validation_data, test_data) = tfds.load(\n",
    "    name=\"imdb_reviews\",\n",
    "    split=(\"train[:60%]\", \"train[60%:]\", \"test\"),\n",
    "    as_supervised=True\n",
    ")\n",
    "\n",
    "# ✅ Check if dataset is loaded\n",
    "print(\"Train Data:\", train_data)\n",
    "print(\"Validation Data:\", validation_data)\n",
    "print(\"Test Data:\", test_data)\n",
    "\n",
    "history = model.fit(\n",
    "    train_data.batch(512),  \n",
    "    epochs=10,\n",
    "    validation_data=validation_data.batch(512),  # ✅ Fixed variable name\n",
    "    verbose=1\n",
    ")\n",
    "print(\"Model Training Done ✅\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2dfb0dc5-ae72-477e-9a94-059014aea424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.6677 - loss: 0.6077\n",
      "Test Accuracy: 0.6720\n"
     ]
    }
   ],
   "source": [
    "# 📌 6. Model Test Karna\n",
    "# Model ko ab test dataset pe check karege.\n",
    "# Agar test accuracy 80-90% tak hai toh model sahi train hua hai. ✅\n",
    "test_loss, test_acc = model.evaluate(test_data.batch(512))\n",
    "print(f'Test Accuracy: {test_acc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ac2ac98a-8727-4b42-a873-def5ed1beb66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved Successfully ✅\n"
     ]
    }
   ],
   "source": [
    "model.save(\"interview_ai_model.h5\")\n",
    "print(\"Model Saved Successfully ✅\")\n",
    "# H5 Format: Yeh TensorFlow ka standard format hai\n",
    "# jo Android App ya Web App me use ho sakta hai."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70926724-23cf-4ee3-9340-10434fb65355",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_review = tf.convert_to_tensor([\"This movie was absolutely fantastic! , Highly recommended!\"], dtype=tf.string)  # ✅ Convert to tf.string tensor\n",
    "prediction = model.predict(sample_review)\n",
    "\n",
    "print(f\"Sentiment Score: {prediction[0][0]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
